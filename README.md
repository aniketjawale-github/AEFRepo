ğŸš€ Azure EdgeFlow â€“ Enterprise Data Engineering Project

ğŸ“Š End-to-End Azure Data Pipeline | Medallion Architecture | Real-World Scenario

---

ğŸ“Œ Overview

**Azure EdgeFlow** is a complete enterprise-grade Data Engineering project simulating real-world use cases using Azure's modern cloud services. It showcases:

- ğŸ”— Data ingestion from GitHub REST API  
- ğŸ§± Medallion Architecture (Bronze â†’ Silver â†’ Gold)  
- âš™ï¸ Transformations using Azure Databricks (PySpark)  
- ğŸ—ƒï¸ Modeling in Azure Synapse Analytics  
- ğŸ“Š Visualization via Power BI

Built to reflect actual **interview use cases**, it uses low/no-code approaches (ADF dynamic pipelines, JSON config) and production best practices.

---

## ğŸ§° Tools & Technologies

| Layer               | Tool/Service Used                |
|---------------------|----------------------------------|
| Ingestion           | Azure Data Factory (ADF)         |
| Storage             | Azure Data Lake Storage Gen2     |
| Processing          | Azure Databricks (PySpark)       |
| Modeling            | Azure Synapse Analytics          |
| Reporting           | Power BI                         |
| Orchestration Logic | JSON Parameterization in ADF     |
| Source Data         | GitHub REST API (CSV format)     |

---

## ğŸ—ï¸ Architecture Diagram
,
                 +-------------------------+
                 |     GitHub API (CSV)    |
                 +-----------+-------------+
                             |
                             â–¼
                    [Azure Data Factory]
                    (Dynamic Copy Activity)
                             |
           +----------------+------------------+
           |                                   |
           â–¼                                   â–¼
     Bronze Zone (Raw) â†’ ADF â†’ Silver Zone (Cleaned) â†’ Databricks â†’ Gold Zone (Modeled)
                                                    |
                                                    â–¼
                                           Azure Synapse Analytics
                                                    |
                                                    â–¼
                                                Power BI

âš™ï¸ Features
âœ… Ingest data from GitHub REST API using ADF (via HTTP linked service)

âœ… Store raw data in Bronze layer using ADLS Gen2

âœ… Use Dynamic Pipelines in ADF with parameterized JSON input (for multiple files)

âœ… Transform data in Databricks (PySpark) and write to Silver layer

âœ… Load transformed data into Azure Synapse Analytics (Gold layer)

âœ… Connect Power BI to Synapse for real-time reporting

âœ… Use of Medallion Architecture (Bronze â†’ Silver â†’ Gold)

âœ… Followed real-world DevOps-style project structure

ğŸš€ Setup Instructions
1ï¸âƒ£ Prerequisites
âœ”ï¸ Azure Account (Free Tier is fine)

âœ”ï¸ GitHub Account

âœ”ï¸ VS Code (optional, for JSON/parameter editing)

âœ”ï¸ Basic knowledge of Azure, Python, SQL

2ï¸âƒ£ Create Required Azure Resources
Azure Resource Group

Azure Data Lake Gen2 (with Hierarchical Namespace)

Azure Data Factory

Azure Databricks Workspace

Azure Synapse Analytics Workspace

(Optional) Power BI Desktop

3ï¸âƒ£ Pipeline Steps
ğŸŸ¤ Phase 1: Ingest Data via ADF
Use Copy Activity to pull data from GitHub API to Bronze layer

Configure Linked Services (HTTP & ADLS)

Use parameterized JSON and ForEach loop for dynamic ingestion

ğŸŸ  Phase 2: Transform with Databricks
Read raw data into Spark DataFrames

Apply transformation logic (filter, enrich, dedupe)

Write cleaned data to Silver zone

ğŸŸ¡ Phase 3: Model in Synapse
Create fact and dimension tables

Load data from Silver into Synapse SQL pool

ğŸ”µ Phase 4: Visualize with Power BI
Connect Power BI to Synapse

Build real-time dashboards using Gold layer



